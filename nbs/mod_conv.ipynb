{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import nn, Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equalized_lr_init(weight: Tensor, bias: Tensor, scale_weights=True, \n",
    "                      lr_mult=1.0) -> float:\n",
    "    fan_in, _ = nn.init._calculate_fan_in_and_fan_out(weight)\n",
    "    he_std = 1.0 / math.sqrt(fan_in)\n",
    "\n",
    "    if scale_weights:\n",
    "        init_std = 1.0 / lr_mult\n",
    "        scale = he_std * lr_mult\n",
    "    else:\n",
    "        init_std = he_std / lr_mult\n",
    "        scale = lr_mult\n",
    "\n",
    "    nn.init.normal_(weight, mean=0.0, std=init_std)\n",
    "    if bias is not None:\n",
    "        nn.init.zeros_(bias)\n",
    "    return scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EqualLinear(nn.Linear):\n",
    "    def __init__(self, in_features, out_features, bias=True, \n",
    "                 scale_weights=True, lr_mult=1.0):\n",
    "        self.scale_weights = scale_weights\n",
    "        self.lr_mult = lr_mult\n",
    "        super(EqualLinear, self).__init__(in_features, out_features, bias)\n",
    "            \n",
    "    def reset_parameters(self):\n",
    "        self.scale = equalized_lr_init(self.weight, self.bias, \n",
    "                                       self.scale_weights, self.lr_mult)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return F.linear(x, self.weight * self.scale, self.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EqualLinear(in_features=4, out_features=8, bias=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "el = EqualLinear(4, 8); el"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 8])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "el(torch.randn(11, 4)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EqualConv2d(nn.Conv2d):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1,\n",
    "                 padding=0, dilation=1, groups=1,\n",
    "                 bias=True, padding_mode='zeros',\n",
    "                 scale_weights=True, lr_mult=1.0):\n",
    "        self.scale_weights = scale_weights\n",
    "        self.lr_mult = lr_mult\n",
    "        super(EqualConv2d, self).__init__(\n",
    "            in_channels, out_channels, kernel_size, stride, padding, \n",
    "            dilation, groups, bias, padding_mode)\n",
    "            \n",
    "    def reset_parameters(self):\n",
    "        self.scale = equalized_lr_init(self.weight, self.bias, \n",
    "                                       self.scale_weights, self.lr_mult)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.conv2d_forward(input, self.weight * self.scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EqualConv2d(4, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ec = EqualConv2d(4, 8, kernel_size=3, padding=1); ec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 8, 12, 12])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ec(torch.randn(3, 4, 12, 12)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ModConv2d(nn.Module):\n",
    "#     def __init__(self, in_channels, out_channels, kernel_size, style_dim, \n",
    "#                  demodulate=True, scale_weights=True, lr_mult=1)\n",
    "#         super(ModConv2d, self).__init__()\n",
    "#         self.style = EqualLinear(style_dim, in_channels, bias=True, \n",
    "#                                  scale_weights=scale_weights, \n",
    "#                                  lr_mult=lr_mult)\n",
    "#         self.conv = EqualConv2d(in_channels, out_channels, kernel_size, \n",
    "#                                 padding=(kernel_size // 2), bias=True, \n",
    "#                                 scale_weights=scale_weights, \n",
    "#                                 lr_mult=lr_mult)\n",
    "#         self.reset_parameters()\n",
    "        \n",
    "#     def reset_parameters(self):\n",
    "#         nn.init.ones_(self.style.bias)\n",
    "        \n",
    "#     def forward(self, x, y):\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModConv2d(nn.Conv2d):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1,\n",
    "                 padding=0, dilation=1, bias=True, \n",
    "                 scale_weights=True, lr_mult=1.0):\n",
    "        self.scale_weights = scale_weights\n",
    "        self.lr_mult = lr_mult\n",
    "        super(ModConv2d, self).__init__(\n",
    "            in_channels, out_channels, kernel_size, stride, padding, \n",
    "            dilation, groups=1, bias=bias, padding_mode='zeros')\n",
    "            \n",
    "    def reset_parameters(self):\n",
    "        self.w_mult = equalized_lr_init(\n",
    "            self.weight, self.bias, self.scale_weights, self.lr_mult)\n",
    "        \n",
    "    def conv2d_forward(self, input, style, weight, bias):\n",
    "        N, C, H, W = input.shape\n",
    "        w = weight[None, :] # OIkk -> NOIkk\n",
    "        \n",
    "        s = style[:, None, :, None, None] # NI -> NOIkk\n",
    "        w = w * s\n",
    "        \n",
    "        d = torch.rsqrt(w.pow(2).sum(dim=(2,3,4), keepdim=True) + 1e-8)\n",
    "        w = w * d\n",
    "        \n",
    "        N, C1, C, Hk, Wk = w.shape\n",
    "        w = w.view(N*C1, C, Hk, Wk)\n",
    "        \n",
    "        x = input.view(1, -1, H, W)\n",
    "        out = F.conv2d(x, w, None, self.stride, self.padding, \n",
    "                     self.dilation, groups=N)\n",
    "        _, _, H1, W1 = out.shape\n",
    "        out = out.view(N, C1, H1, W1)\n",
    "        \n",
    "        if bias is not None:\n",
    "            out = out + bias[:, None, None]\n",
    "        return out\n",
    "\n",
    "    def forward(self, input, style):\n",
    "        weight = self.weight * self.w_mult\n",
    "        if self.bias is not None:\n",
    "            bias = self.bias * self.lr_mult\n",
    "        else:\n",
    "            bias = None\n",
    "        return self.conv2d_forward(input, style, weight, bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModConv2d(4, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc = ModConv2d(4, 8, 3, padding=1, bias=True); mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 8, 12, 12])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc(\n",
    "    torch.randn(7, 4, 12, 12),\n",
    "    torch.randn(7, 4)\n",
    ").shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:latest] *",
   "language": "python",
   "name": "conda-env-latest-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
