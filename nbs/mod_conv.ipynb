{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import nn, Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.stylegan2.layers import EqualConv2d, EqualLinear, EqualLeakyReLU, \\\n",
    "    ModulatedConv2d, RandomGaussianNoise\n",
    "\n",
    "from models.stylegan2.net import Layer, ToRGB, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: 18\n",
      "\n",
      "0: 512\n",
      "1: 512\n",
      "2: 512\n",
      "3: 512\n",
      "4: 512\n",
      "5: 512\n",
      "6: 256\n",
      "7: 128\n",
      "8: 64\n",
      "9: 32\n",
      "10: 16\n"
     ]
    }
   ],
   "source": [
    "def nf(stage): \n",
    "    fmap_base=16 << 10\n",
    "    fmap_decay=1.0\n",
    "    fmap_min=1\n",
    "    fmap_max=512\n",
    "    \n",
    "    fmaps = int(fmap_base / (2.0 ** (stage * fmap_decay)))\n",
    "    return np.clip(fmaps, fmap_min, fmap_max)\n",
    "\n",
    "res_log2 = int(math.log2(1024))\n",
    "num_layers = res_log2 * 2 - 2\n",
    "print(f'n: {num_layers}\\n')\n",
    "\n",
    "for i in range(res_log2 + 1):\n",
    "    print(f'{i}: {nf(i)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 1 2\n",
      "3 4 2 3\n",
      "5 6 3 4\n",
      "7 8 4 5\n",
      "9 10 5 6\n",
      "11 12 6 7\n",
      "13 14 7 8\n",
      "15 16 8 9\n"
     ]
    }
   ],
   "source": [
    "for res in range(3, res_log2 + 1):\n",
    "    print(res*2-5, res*2-4, res-2, res-1)\n",
    "    \n",
    "# for res in range(3, res_log2 + 1):\n",
    "#     stage = (res - 2) * 2\n",
    "#     print(stage-1, stage)\n",
    "    \n",
    "    \n",
    "# for res in range(res_log2 - 2):\n",
    "#     stage = res * 2 + 1\n",
    "#     print(stage, stage+1, res+1, res+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "5\n",
      "7\n",
      "9\n",
      "11\n",
      "13\n",
      "15\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "for res in range(3, res_log2 + 1):\n",
    "    print(res*2-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upscale(x, factor):\n",
    "    return F.interpolate(x, scale_factor=factor, mode='bilinear', align_corners=False)\n",
    "\n",
    "\n",
    "class SynthesisNet(nn.Module):\n",
    "    def __init__(self, img_res=1024, img_channels=3, style_dim=512,\n",
    "                 fmap_base=16 << 10, fmap_decay=1.0, fmap_min=1, fmap_max=512):\n",
    "        super(SynthesisNet, self).__init__()\n",
    "\n",
    "        if img_res <= 4:\n",
    "            raise AttributeError(\"Image resolution must be greater than 4\")\n",
    "\n",
    "        res_log2 = int(math.log2(img_res))\n",
    "        if img_res != 2 ** res_log2:\n",
    "            raise AttributeError(\"Image resolution must be a power of 2\")\n",
    "\n",
    "        self.res_log2 = res_log2\n",
    "\n",
    "        def nf(stage):\n",
    "            fmaps = int(fmap_base / (2.0 ** (stage * fmap_decay)))\n",
    "            return np.clip(fmaps, fmap_min, fmap_max)\n",
    "\n",
    "        main = [Layer(nf(1), nf(1), style_dim)]\n",
    "        outs = [ToRGB(nf(1), img_channels, style_dim)]\n",
    "\n",
    "        for res in range(1, res_log2 - 1):\n",
    "            inp_ch, out_ch = nf(res), nf(res + 1)\n",
    "            main += [Layer(inp_ch, out_ch, style_dim, up=True),\n",
    "                     Layer(out_ch, out_ch, style_dim)]\n",
    "            outs += [ToRGB(out_ch, img_channels, style_dim)]\n",
    "\n",
    "        self.input = Input(nf(1), size=4)\n",
    "        self.main = nn.ModuleList(main)\n",
    "        self.outs = nn.ModuleList(outs)\n",
    "\n",
    "    def forward(self, n):\n",
    "        w = torch.rand(len(self.main) + 1, n, 512)\n",
    "        x = self.input(n)\n",
    "        y = None\n",
    "        for i, layer in enumerate(self.main):\n",
    "            x = layer(x, w[i])\n",
    "            if not i % 2:\n",
    "                out = self.outs[i//2]\n",
    "                if not i:\n",
    "                    y = out(x, w[i+1])\n",
    "                else:\n",
    "                    y = upscale(y, 2) + out(x, w[i+1])\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn = SynthesisNet(\n",
    "    img_res=32,\n",
    "    fmap_base=2<<6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 32, 32])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sn(3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalize(nn.Module):\n",
    "    def forward(self, x):\n",
    "        norm = torch.rsqrt(x.pow(2).mean(dim=1, keepdim=True) + 1e-8)\n",
    "        return x * norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbedLabels(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(EmbedLabels, self).__init__()\n",
    "        self.linear = nn.Linear(in_features, out_features, bias=False)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.normal_(self.linear.weight)\n",
    "        \n",
    "    def forward(self, z, y):\n",
    "        y = self.linear(y)\n",
    "        return torch.cat([z, y], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 64])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EmbedLabels(4, 32)(\n",
    "    torch.rand(3, 32),\n",
    "    torch.rand(3, 4)\n",
    ").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MappingNet(nn.Module):\n",
    "    def __init__(self, latent_dim=512, label_dim=0, out_dim=512, \n",
    "                 num_layers=8, fmaps=512, lr_mult=0.01, normalize=True):\n",
    "        super(MappingNet, self).__init__()\n",
    "        in_fmaps = latent_dim\n",
    "        self.embed_labels = None\n",
    "        \n",
    "        if label_dim > 0:\n",
    "            self.embed_labels = EmbedLabels(label_dim, latent_dim)\n",
    "            in_fmaps = latent_dim * 2\n",
    "            \n",
    "        layers = [Normalize()] if normalize else []\n",
    "        features = [in_fmaps] + [fmaps]*(num_layers-1) + [out_dim]\n",
    "        for i in range(num_layers):\n",
    "            layers += [EqualLinear(features[i], features[i+1], lr_mult=lr_mult), \n",
    "                       EqualLeakyReLU(inplace=True)]\n",
    "        self.mapping = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, z, y=None):\n",
    "        if self.embed_labels:\n",
    "            z = self.embed_labels(z, y)\n",
    "        z = self.mapping(z)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn = MappingNet(latent_dim=32, label_dim=7, out_dim=32, num_layers=8, fmaps=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mn(torch.rand(3, 32), torch.rand(3, 7)).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:latest] *",
   "language": "python",
   "name": "conda-env-latest-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
