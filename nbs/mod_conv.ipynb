{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import nn, Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.stylegan2.layers import EqualConv2d, EqualLinear, EqualLeakyReLU, \\\n",
    "    ModulatedConv2d, RandomGaussianNoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StyledLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, style_dim, up=False):\n",
    "        super(StyledLayer, self).__init__()\n",
    "        self.style = EqualLinear(style_dim, in_channels, bias=True)\n",
    "        nn.init.ones_(self.style.bias)\n",
    "        \n",
    "        if up:\n",
    "            self.upscale = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        else:\n",
    "            self.upscale = None\n",
    "            \n",
    "        self.conv = ModulatedConv2d(in_channels, out_channels, kernel_size=3, \n",
    "                                    stride=1, padding=1)\n",
    "        self.add_noise = RandomGaussianNoise()\n",
    "        self.act_fn = EqualLeakyReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, x, w):\n",
    "        if self.upscale is not None:\n",
    "            x = self.upscale(x)\n",
    "        y = self.style(w)\n",
    "        x = self.conv(x, y)\n",
    "        x = self.act_fn(self.add_noise(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StyledLayer(\n",
       "  (style): EqualLinear(in_features=24, out_features=4, bias=True)\n",
       "  (conv): ModulatedConv2d(4, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (add_noise): RandomGaussianNoise()\n",
       "  (act_fn): EqualLeakyReLU(negative_slope=0.2, inplace=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sl = StyledLayer(\n",
    "    in_channels=4, \n",
    "    out_channels=8, \n",
    "    style_dim=24,\n",
    "    up=False\n",
    "); sl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 32, 32])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(1, 4, 32, 32)\n",
    "w = torch.rand(1, 24)\n",
    "\n",
    "sl(x, w).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StyledBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, style_dim):\n",
    "        super(StyledBlock, self).__init__()\n",
    "        \n",
    "    def forward(self, x, w):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SynthesisNet(nn.Module):\n",
    "    def __init__(self, style_dim=512, out_channels=3, out_res=1024, \n",
    "                 fmap_base=16 << 10, fmap_decay=1.0, fmap_min=1, fmap_max=512):\n",
    "        super(SynthesisNet, self).__init__()\n",
    "        \n",
    "        if out_res <= 4:\n",
    "            raise AttributeError(\"The output resolution must be greater than 4\")\n",
    "            \n",
    "        res_log2 = int(math.log2(out_res))\n",
    "        if out_res != 2**res_log2:\n",
    "            raise AttributeError(\"The output resolution must be a power of 2\")\n",
    "        \n",
    "        def nf(stage): \n",
    "            fmaps = int(fmap_base / (2.0 ** (stage * fmap_decay)))\n",
    "            return np.clip(fmaps, fmap_min, fmap_max)\n",
    "        \n",
    "        num_layers = res_log2 * 2 - 2\n",
    "        \n",
    "    def forward():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToRGB(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, style_dim):\n",
    "        super(ToRGB, self).__init__()\n",
    "        self.style = EqualLinear(style_dim, in_channels, bias=True)\n",
    "        nn.init.ones_(self.style.bias)\n",
    "        \n",
    "        self.conv = ModulatedConv2d(in_channels, out_channels, kernel_size=1, \n",
    "                                    stride=1, padding=0, demodulate=False)\n",
    "        \n",
    "    def forward(self, x, w, x0=None):\n",
    "        x = self.conv(x, self.style(w))\n",
    "        if x0 is not None:\n",
    "            x = x + x0\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trgb = ToRGB(4, 8, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 12, 12])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trgb(\n",
    "    torch.rand(1, 4, 12, 12),\n",
    "    torch.rand(1, 24)\n",
    ").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputNoise(nn.Module):\n",
    "    def __init__(self, channels, size=4):\n",
    "        super(InputNoise, self).__init__()\n",
    "        self.weight = nn.Parameter(torch.empty(1, channels, size, size),\n",
    "                                   requires_grad=True)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.normal_(self.weight)\n",
    "\n",
    "    def forward(self, n):\n",
    "        x = self.weight.expand(n, -1, -1, -1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = InputNoise(512, size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 512, 4, 4])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp(11).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:latest] *",
   "language": "python",
   "name": "conda-env-latest-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
